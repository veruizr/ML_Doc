{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1AMXIcVQNi8bYr6vDuY0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veruizr/ML_Doc/blob/main/Tarea3_reglas_asociaci%C3%B3n/reglas_de_asociacion_corregido.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reglas de asociación\n",
        "Implemente utilizando Polars los siguientes algoritmos para encontrar reglas de asociación:·\n",
        "\n",
        "1. Apriori\n",
        "\n",
        "2. FP-Growth\n",
        "\n",
        "3. Compare ambos algoritmos con el mismo conjunto de datos"
      ],
      "metadata": {
        "id": "vAGHfz0jqk9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datos a utilizar propuestos en clase\n",
        "\n",
        "| Cliente | Productos              |\n",
        "|---------|------------------------|\n",
        "| 1       | a, c, d, f, g, i, m, p |\n",
        "| 2       | a, b, c, f, l, m, o    |\n",
        "| 3       | b, f, h, j, o          |\n",
        "| 4       | b, c, k, s, p          |\n",
        "| 5       | a, c, e, f, l, m, n, p |\n"
      ],
      "metadata": {
        "id": "brcIx0p_rHJB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1ZRSn9gZ1Uj",
        "outputId": "85b550a0-e5aa-4c30-d301-36af3e2714bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-ecb7378b3e57>:13: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
            "  df = pl.DataFrame(data, schema=[\"Cliente\", \"Productos\"])\n"
          ]
        }
      ],
      "source": [
        "import polars as pl\n",
        "\n",
        "# Datos de ejemplo\n",
        "data = [\n",
        "    [1, \"a,c,d,f,g,i,m,p\"],\n",
        "    [2, \"a,b,c,f,l,m,o\"],\n",
        "    [3, \"b,f,h,j,o\"],\n",
        "    [4, \"b,c,k,s,p\"],\n",
        "    [5, \"a,c,e,f,l,m,n,p\"]\n",
        "]\n",
        "\n",
        "# Crear DataFrame\n",
        "df = pl.DataFrame(data, schema=[\"Cliente\", \"Productos\"])\n",
        "\n",
        "# Separar los productos en listas\n",
        "df = df.with_columns([\n",
        "    pl.col(\"Productos\").str.split(\",\").alias(\"Productos_list\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Algoritmo Apriori\n",
        "\n",
        "1. Genera conjuntos candidatos de tamaño k a partir de los frecuentes de tamaño k-1.\n",
        "\n",
        "2. Cuenta el soporte de cada conjunto candidato.\n",
        "\n",
        "3. Elimina los que no cumplen el soporte mínimo.\n",
        "\n",
        "4. Repite hasta que no haya más candidatos."
      ],
      "metadata": {
        "id": "xUY0b2mcaO2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import tracemalloc\n",
        "\n",
        "def apriori(transactions, min_support):\n",
        "\n",
        "    item_counts = defaultdict(int)\n",
        "    for transaction in transactions:\n",
        "        for item in transaction:\n",
        "            item_counts[frozenset([item])] += 1\n",
        "\n",
        "    num_transactions = len(transactions)\n",
        "    freq_itemsets = {1: {item for item, count in item_counts.items() if count/num_transactions >= min_support}}\n",
        "    all_freq_itemsets = set(freq_itemsets[1])\n",
        "    k = 2\n",
        "\n",
        "    while True:\n",
        "        candidates = set([\n",
        "            frozenset(i.union(j))\n",
        "            for i in freq_itemsets[k-1]\n",
        "            for j in freq_itemsets[k-1]\n",
        "            if len(i.union(j)) == k\n",
        "        ])\n",
        "        candidate_counts = defaultdict(int)\n",
        "        for transaction in transactions:\n",
        "            t_set = set(transaction)\n",
        "            for candidate in candidates:\n",
        "                if candidate.issubset(t_set):\n",
        "                    candidate_counts[candidate] += 1\n",
        "        freq_k = {c for c, count in candidate_counts.items() if count/num_transactions >= min_support}\n",
        "        if not freq_k:\n",
        "            break\n",
        "        freq_itemsets[k] = freq_k\n",
        "        all_freq_itemsets.update(freq_k)\n",
        "        k += 1\n",
        "\n",
        "\n",
        "    return all_freq_itemsets\n",
        "\n",
        "\n",
        "#Generar Reglas de asociación\n",
        "def generate_rules_ap(freq_itemsets, transactions, min_confidence):\n",
        "    rules_apriori = []\n",
        "    num_transactions = len(transactions)\n",
        "    for itemset in freq_itemsets:\n",
        "        if len(itemset) < 2:\n",
        "            continue\n",
        "        for antecedent_size in range(1, len(itemset)):\n",
        "            for antecedent in itertools.combinations(itemset, antecedent_size):\n",
        "                antecedent = frozenset(antecedent)\n",
        "                consequent = itemset - antecedent\n",
        "                support_itemset = sum(1 for t in transactions if itemset.issubset(t)) / num_transactions\n",
        "                support_antecedent = sum(1 for t in transactions if antecedent.issubset(t)) / num_transactions\n",
        "                support_consequent = sum(1 for t in transactions if consequent.issubset(t)) / num_transactions\n",
        "                confidence = support_itemset / support_antecedent if support_antecedent > 0 else 0\n",
        "                lift = confidence / support_consequent if support_consequent > 0 else 0\n",
        "                if confidence >= min_confidence:\n",
        "                    rules_apriori.append({\n",
        "                        \"antecedent\": antecedent,\n",
        "                        \"consequent\": consequent,\n",
        "                        \"support\": support_itemset,\n",
        "                        \"confidence\": confidence,\n",
        "                        \"lift\": lift\n",
        "                    })\n",
        "    return rules_apriori\n",
        "\n",
        "\n",
        "# Aplicación\n",
        "transactions = df[\"Productos_list\"].to_list()\n",
        "min_support = 0.4\n",
        "min_confidence=0.67\n",
        "\n",
        "# Inicio Medición de desempeño\n",
        "tracemalloc.start()\n",
        "start_time = time.time()\n",
        "\n",
        "#obtener itemset a-priori\n",
        "apriori_itemsets = apriori(transactions, min_support)\n",
        "\n",
        "#generar reglas de aosciación A-priori\n",
        "rules_apriori_df = pl.DataFrame(generate_rules_ap(freq_itemsets=apriori_itemsets,transactions=transactions,min_confidence=min_confidence))\n",
        "\n",
        "#finalizar medición de desempeño\n",
        "end_time = time.time()\n",
        "current, peak = tracemalloc.get_traced_memory()\n",
        "tracemalloc.stop()\n",
        "\n",
        "# Desempeño\n",
        "execution_time_ap = end_time - start_time\n",
        "memory_used_MB_ap = peak / (1024 * 1024)\n",
        "\n",
        "#resultados\n",
        "apriori_itemsets_df = pl.DataFrame({\n",
        "    \"itemset\": [str(k) for k in apriori_itemsets],\n",
        "    \"support_count\": [1] * len(apriori_itemsets)\n",
        "})\n",
        "print(\"\\Frequent Itemsets:\")\n",
        "\n",
        "print(apriori_itemsets_df)\n",
        "\n",
        "print(\"\\nAssociation Rules:\")\n",
        "print(rules_apriori_df)\n",
        "\n",
        "print(f\"\\nExecution Time: {execution_time_ap:.4f} seconds\")\n",
        "print(f\"Peak Memory Usage: {memory_used_MB_ap:.4f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtxYOa11aT8v",
        "outputId": "6719212b-5122-4d02-896e-aecba9387ab7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\Frequent Itemsets:\n",
            "shape: (54, 2)\n",
            "┌─────────────────────────────────┬───────────────┐\n",
            "│ itemset                         ┆ support_count │\n",
            "│ ---                             ┆ ---           │\n",
            "│ str                             ┆ i64           │\n",
            "╞═════════════════════════════════╪═══════════════╡\n",
            "│ frozenset({'c', 'f', 'l'})      ┆ 1             │\n",
            "│ frozenset({'m', 'c', 'a', 'f',… ┆ 1             │\n",
            "│ frozenset({'m'})                ┆ 1             │\n",
            "│ frozenset({'c', 'l'})           ┆ 1             │\n",
            "│ frozenset({'f', 'a', 'l'})      ┆ 1             │\n",
            "│ …                               ┆ …             │\n",
            "│ frozenset({'f', 'm'})           ┆ 1             │\n",
            "│ frozenset({'f', 'p', 'm'})      ┆ 1             │\n",
            "│ frozenset({'f', 'l'})           ┆ 1             │\n",
            "│ frozenset({'f', 'o', 'b'})      ┆ 1             │\n",
            "│ frozenset({'b'})                ┆ 1             │\n",
            "└─────────────────────────────────┴───────────────┘\n",
            "\n",
            "Association Rules:\n",
            "shape: (166, 5)\n",
            "┌───────────────────────┬─────────────────────────────────┬─────────┬────────────┬──────────┐\n",
            "│ antecedent            ┆ consequent                      ┆ support ┆ confidence ┆ lift     │\n",
            "│ ---                   ┆ ---                             ┆ ---     ┆ ---        ┆ ---      │\n",
            "│ object                ┆ object                          ┆ f64     ┆ f64        ┆ f64      │\n",
            "╞═══════════════════════╪═════════════════════════════════╪═════════╪════════════╪══════════╡\n",
            "│ frozenset({'l'})      ┆ frozenset({'c', 'f'})           ┆ 0.4     ┆ 1.0        ┆ 1.666667 │\n",
            "│ frozenset({'c', 'l'}) ┆ frozenset({'f'})                ┆ 0.4     ┆ 1.0        ┆ 1.25     │\n",
            "│ frozenset({'f', 'l'}) ┆ frozenset({'c'})                ┆ 0.4     ┆ 1.0        ┆ 1.25     │\n",
            "│ frozenset({'l'})      ┆ frozenset({'f', 'c', 'a', 'm'}… ┆ 0.4     ┆ 1.0        ┆ 1.666667 │\n",
            "│ frozenset({'l', 'm'}) ┆ frozenset({'f', 'c', 'a'})      ┆ 0.4     ┆ 1.0        ┆ 1.666667 │\n",
            "│ …                     ┆ …                               ┆ …       ┆ …          ┆ …        │\n",
            "│ frozenset({'l'})      ┆ frozenset({'f'})                ┆ 0.4     ┆ 1.0        ┆ 1.25     │\n",
            "│ frozenset({'o'})      ┆ frozenset({'f', 'b'})           ┆ 0.4     ┆ 1.0        ┆ 2.5      │\n",
            "│ frozenset({'f', 'o'}) ┆ frozenset({'b'})                ┆ 0.4     ┆ 1.0        ┆ 1.666667 │\n",
            "│ frozenset({'f', 'b'}) ┆ frozenset({'o'})                ┆ 0.4     ┆ 1.0        ┆ 2.5      │\n",
            "│ frozenset({'o', 'b'}) ┆ frozenset({'f'})                ┆ 0.4     ┆ 1.0        ┆ 1.25     │\n",
            "└───────────────────────┴─────────────────────────────────┴─────────┴────────────┴──────────┘\n",
            "\n",
            "Execution Time: 0.0309 seconds\n",
            "Peak Memory Usage: 0.1200 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Algoritmo FP-Growth\n",
        "\n",
        "1. Construye un FP-tree (árbol de patrones frecuentes) a partir de las transacciones.\n",
        "\n",
        "2. Extrae los conjuntos frecuentes sin generar candidatos explícitos, usando proyecciones recursivas del árbol."
      ],
      "metadata": {
        "id": "9SpMV0RBmKU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "#from collections import defaultdict\n",
        "from itertools import combinations\n",
        "#import time\n",
        "\n",
        "\n",
        "# Parámetros\n",
        "min_support = 0.4\n",
        "min_confidence = 0.67\n",
        "\n",
        "# Total de transacciones\n",
        "num_transactions = len(transactions)\n",
        "min_support_count = min_support * num_transactions\n",
        "\n",
        "# Función para obtener todos los itemsets frecuentes (nivel 1 y combinaciones)\n",
        "def get_frequent_itemsets(transactions, min_support_count):\n",
        "    item_counts = defaultdict(int)\n",
        "\n",
        "    # Contar frecuencia de todos los ítems y combinaciones\n",
        "    for transaction in transactions:\n",
        "        for i in range(1, len(transaction)+1):\n",
        "            for subset in combinations(sorted(transaction), i):\n",
        "                item_counts[subset] += 1\n",
        "\n",
        "    # Filtrar por min_support\n",
        "    freq_itemsets = {items: count for items, count in item_counts.items() if count >= min_support_count}\n",
        "\n",
        "    return freq_itemsets\n",
        "\n",
        "# Función para generar reglas de asociación\n",
        "\n",
        "def generate_rules_fpg(freq_itemsets, num_transactions, min_confidence):\n",
        "    rules_fpg = []\n",
        "\n",
        "    for itemset in freq_itemsets:\n",
        "        if len(itemset) < 2:\n",
        "            continue  # No se pueden generar reglas de 1 solo ítem\n",
        "        itemset_support = freq_itemsets[itemset] / num_transactions\n",
        "\n",
        "        for i in range(1, len(itemset)):\n",
        "            for antecedent in combinations(itemset, i):\n",
        "                consequent = tuple(sorted(set(itemset) - set(antecedent)))\n",
        "                antecedent_count = freq_itemsets.get(tuple(sorted(antecedent)), 0)\n",
        "\n",
        "                if antecedent_count == 0:\n",
        "                    continue\n",
        "\n",
        "                confidence = freq_itemsets[itemset] / antecedent_count\n",
        "\n",
        "                if confidence >= min_confidence:\n",
        "                    rules_fpg.append({\n",
        "                        'antecedent': antecedent,\n",
        "                        'consequent': consequent,\n",
        "                        'support': round(itemset_support, 3),\n",
        "                        'confidence': round(confidence, 3)\n",
        "                    })\n",
        "    return rules_fpg\n",
        "\n",
        "# iniciar Medición de desempeño\n",
        "tracemalloc.start()\n",
        "start_time = time.time()\n",
        "\n",
        "# 1. Obtener itemsets frecuentes\n",
        "freq_itemsets = get_frequent_itemsets(transactions, min_support_count)\n",
        "\n",
        "# 2. Generar reglas de asociación\n",
        "rules_fpg = generate_rules_fpg(freq_itemsets, num_transactions, min_confidence)\n",
        "\n",
        "#finalizar medición de desempeño\n",
        "end_time = time.time()\n",
        "current, peak = tracemalloc.get_traced_memory()\n",
        "tracemalloc.stop()\n",
        "\n",
        "# Desempeño\n",
        "execution_time_fpg = end_time - start_time\n",
        "memory_used_MB_fpg = peak / (1024 * 1024)\n",
        "\n",
        "# Resultados\n",
        "frequent_itemsets_df = pl.DataFrame({\n",
        "    \"itemset\": [str(k) for k in freq_itemsets.keys()],\n",
        "    \"support_count\": list(freq_itemsets.values())\n",
        "})\n",
        "rules_fpg_df = pl.DataFrame(rules_fpg)\n",
        "\n",
        "print(\"Frequent Itemsets:\")\n",
        "print(frequent_itemsets_df)\n",
        "\n",
        "print(\"\\nAssociation Rules:\")\n",
        "print(rules_fpg_df)\n",
        "\n",
        "print(f\"\\nExecution Time: {execution_time_fpg:.4f} seconds\")\n",
        "print(f\"Peak Memory Usage: {memory_used_MB_fpg:.4f} MB\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Muo-ZHlbiE6",
        "outputId": "58ba7565-332e-4872-f4f0-f88fffa51781"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "shape: (54, 2)\n",
            "┌───────────────────────────┬───────────────┐\n",
            "│ itemset                   ┆ support_count │\n",
            "│ ---                       ┆ ---           │\n",
            "│ str                       ┆ i64           │\n",
            "╞═══════════════════════════╪═══════════════╡\n",
            "│ ('a',)                    ┆ 3             │\n",
            "│ ('c',)                    ┆ 4             │\n",
            "│ ('f',)                    ┆ 4             │\n",
            "│ ('m',)                    ┆ 3             │\n",
            "│ ('p',)                    ┆ 3             │\n",
            "│ …                         ┆ …             │\n",
            "│ ('a', 'c', 'f', 'l')      ┆ 2             │\n",
            "│ ('a', 'c', 'l', 'm')      ┆ 2             │\n",
            "│ ('a', 'f', 'l', 'm')      ┆ 2             │\n",
            "│ ('c', 'f', 'l', 'm')      ┆ 2             │\n",
            "│ ('a', 'c', 'f', 'l', 'm') ┆ 2             │\n",
            "└───────────────────────────┴───────────────┘\n",
            "\n",
            "Association Rules:\n",
            "shape: (166, 4)\n",
            "┌───────────────────┬────────────┬─────────┬────────────┐\n",
            "│ antecedent        ┆ consequent ┆ support ┆ confidence │\n",
            "│ ---               ┆ ---        ┆ ---     ┆ ---        │\n",
            "│ list[str]         ┆ list[str]  ┆ f64     ┆ f64        │\n",
            "╞═══════════════════╪════════════╪═════════╪════════════╡\n",
            "│ [\"a\"]             ┆ [\"c\"]      ┆ 0.6     ┆ 1.0        │\n",
            "│ [\"c\"]             ┆ [\"a\"]      ┆ 0.6     ┆ 0.75       │\n",
            "│ [\"a\"]             ┆ [\"f\"]      ┆ 0.6     ┆ 1.0        │\n",
            "│ [\"f\"]             ┆ [\"a\"]      ┆ 0.6     ┆ 0.75       │\n",
            "│ [\"a\"]             ┆ [\"m\"]      ┆ 0.6     ┆ 1.0        │\n",
            "│ …                 ┆ …          ┆ …       ┆ …          │\n",
            "│ [\"f\", \"l\", \"m\"]   ┆ [\"a\", \"c\"] ┆ 0.4     ┆ 1.0        │\n",
            "│ [\"a\", \"c\", … \"l\"] ┆ [\"m\"]      ┆ 0.4     ┆ 1.0        │\n",
            "│ [\"a\", \"c\", … \"m\"] ┆ [\"f\"]      ┆ 0.4     ┆ 1.0        │\n",
            "│ [\"a\", \"f\", … \"m\"] ┆ [\"c\"]      ┆ 0.4     ┆ 1.0        │\n",
            "│ [\"c\", \"f\", … \"m\"] ┆ [\"a\"]      ┆ 0.4     ┆ 1.0        │\n",
            "└───────────────────┴────────────┴─────────┴────────────┘\n",
            "\n",
            "Execution Time: 0.0117 seconds\n",
            "Peak Memory Usage: 0.0857 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Comparación"
      ],
      "metadata": {
        "id": "tQBEtsMpOywp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "performance = pl.DataFrame({\n",
        "    \"Algorithn\": [\"Apriori\", \"FP-Growth\"],\n",
        "    \"Execution_time s\": [execution_time_ap, execution_time_fpg],\n",
        "    \"Memoria_MB\": [memory_used_MB_ap, memory_used_MB_fpg]\n",
        "})\n",
        "print(\"\\nDesempeño comparado en ejecución:\")\n",
        "print(performance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_YFtLDGTA9B",
        "outputId": "505d406f-1cc6-4b4c-ac05-c8624c45226a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Desempeño comparado en ejecución:\n",
            "shape: (2, 3)\n",
            "┌───────────┬──────────────────┬────────────┐\n",
            "│ Algorithn ┆ Execution_time s ┆ Memoria_MB │\n",
            "│ ---       ┆ ---              ┆ ---        │\n",
            "│ str       ┆ f64              ┆ f64        │\n",
            "╞═══════════╪══════════════════╪════════════╡\n",
            "│ Apriori   ┆ 0.030927         ┆ 0.120027   │\n",
            "│ FP-Growth ┆ 0.011748         ┆ 0.085674   │\n",
            "└───────────┴──────────────────┴────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "se plantea la siguiente tabla comparativa respecto a la implementación y la ejecución de los dos algoritmos\n",
        "\n",
        "| Criterio         | Apriori                                     | FP-Growth                                |\n",
        "|------------------|---------------------------------------------|------------------------------------------|\n",
        "| Estructura       | Genera candidatos y escanea la base muchas veces | Construye un FP-tree, escanea solo dos veces |\n",
        "| Uso de memoria   | Mayor, por generación de candidatos         | Menor, estructura compacta               |\n",
        "| Tiempo de ejecución | Más lento | Más rápido y eficiente                   |\n",
        "| Escalabilidad    | Limitada por el número de candidatos        | Mejor, pero el árbol puede crecer mucho  |\n"
      ],
      "metadata": {
        "id": "8RH8v7wghu69"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xVvn1Q6aiwCe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}